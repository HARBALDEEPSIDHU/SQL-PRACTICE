**Data Science Skills

SELECT CANDIDATE_ID
FROM CANDIDATES
WHERE SKILL IN ('Python', 'Tableau' , 'PostgreSQL')
GROUP BY CANDIDATE_ID
HAVING COUNT(SKILL)= 3
ORDER BY CANDIDATE_ID;

**Page With No Likes

SELECT PAGES.PAGE_ID
FROM PAGES
LEFT OUTER JOIN PAGE_LIKES
ON PAGES.PAGE_ID = PAGE_LIKES.PAGE_ID
WHERE PAGE_LIKES.PAGE_ID IS NULL;

**Unfinished Parts
SELECT DISTINCT PART
FROM PARTS_ASSEMBLY 
WHERE FINISH_DATE IS NULL;

**Laptop vs. Mobile Viewership

SELECT 
SUM(CASE WHEN DEVICE_TYPE = 'laptop' THEN 1 ELSE 0 END) AS LAPTOP_VIEWS,
SUM(CASE WHEN DEVICE_TYPE IN ('phone' , 'tablet') THEN 1 ELSE 0 END) AS MOBILE_VIEWS
FROM VIEWERSHIP;

**Cities With Completed Trades

SELECT 
USERS.CITY,
COUNT(TRADES.ORDER_ID) AS TOTAL_ORDERS
FROM TRADES LEFT JOIN USERS ON
USERS.USER_ID = TRADES.USER_ID
WHERE TRADES.STATUS = 'Completed'
GROUP BY USERS.CITY 
ORDER BY TOTAL_ORDERS DESC
LIMIT 3;

**Duplicate Job Listings

COUNT(DISTINCT (COMPANY_ID )) AS co_w_duplicate_jobs
FROM
(SELECT COMPANY_ID, TITLE, DESCRIPTION, 
COUNT(JOB_ID) AS JOB_COUNT 
FROM JOB_LISTINGS
GROUP BY COMPANY_ID, TITLE, DESCRIPTION) AS JOBS_GROUPED
WHERE JOB_COUNT>1;


**Final Account Balance

SELECT
ACCOUNT_ID ,
 SUM(CASE WHEN TRANSACTION_TYPE = 'Deposit' THEN AMOUNT ELSE -AMOUNT END) 
AS FINAL_BALANCE
FROM TRANSACTIONS
GROUP BY ACCOUNT_ID;

**Histogram of Tweets

SELECT
TWEETS_NUM AS TWEET_BUCKET,
COUNT(USER_ID) AS USER_NUM
FROM(
SELECT 
USER_ID,
COUNT(TWEET_ID) AS TWEETS_NUM
FROM TWEETS
WHERE TWEET_DATE BETWEEN '2022-01-01' AND '2022-12-31' 
GROUP BY USER_ID
)
AS TOTAL_TWEETS
GROUP BY TWEETS_NUM;

**Average Review Ratings

SELECT 
EXTRACT(MONTH FROM SUBMIT_DATE) AS MTH,
 PRODUCT_ID,
ROUND(AVG(STARS), 2) AS AVG_STARS
FROM REVIEWS
GROUP BY EXTRACT(MONTH FROM SUBMIT_DATE) , PRODUCT_ID
ORDER BY MTH , PRODUCT_ID;

**LinkedIn Power Creators (Part 1)

SELECT  PP.PROFILE_ID
FROM PERSONAL_PROFILES AS PP
JOIN COMPANY_PAGES AS CP
ON PP.EMPLOYER_ID = CP.COMPANY_ID
WHERE PP.FOLLOWERS > CP.FOLLOWERS
ORDER BY PP.PROFILE_ID;

**Highest Number of Products

SELECT USER_ID , COUNT(PRODUCT_ID) AS PRODUCT_NUM
FROM USER_TRANSACTIONS
GROUP  BY USER_ID
HAVING SUM(SPEND) > 1000
ORDER BY PRODUCT_NUM DESC ,
SUM(SPEND) DESC
LIMIT 3;

**Spare Server Capacity

WITH TOTAL_DEMAND AS (
SELECT  DATACENTER_ID,
SUM(MONTHLY_DEMAND) AS TOTAL_DEMAND
FROM FORECASTED_DEMAND
GROUP BY DATACENTER_ID)

SELECT TD.DATACENTER_ID, 
(D.MONTHLY_CAPACITY - TD.TOTAL_DEMAND) AS SPARE_CAPACITY 
FROM DATACENTERS AS D JOIN TOTAL_DEMAND AS TD
ON D.DATACENTER_ID =TD.DATACENTER_ID
ORDER BY DATACENTER_ID; 

**Average Post Hiatus (Part 1)

SELECT USER_ID ,
MAX(POST_DATE:: DATE) - MIN(POST_DATE:: DATE) AS DAYS_BETWEEN
FROM POSTS
WHERE DATE_PART('year' , POST_DATE::DATE) = 2021
GROUP  BY USER_ID
HAVING COUNT(POST_ID)>1;

**Teams Power Users

SELECT SENDER_ID ,
COUNT(MESSAGE_ID) AS MESSAGE_COUNT
FROM MESSAGES
WHERE EXTRACT(MONTH FROM SENT_DATE) = '8'
AND EXTRACT(YEAR FROM SENT_DATE) = '2022'
GROUP BY SENDER_ID
ORDER BY MESSAGE_COUNT DESC
LIMIT 2

**Top Rated Businesses

SELECT COUNT(BUSINESS_ID) AS BUSINESS_COUNT,
ROUND( 100.0 * COUNT(BUSINESS_ID)/
(SELECT COUNT(BUSINESS_ID) FROM REVIEWS),0) AS TOP_RATED_PCT
FROM REVIEWS
WHERE REVIEW_STARS IN (4,5);

**Ad Campaign ROAS

SELECT ADVERTISER_ID ,ROUND(((SUM(REVENUE) / SUM(SPEND)):: DECIMAL) , 2)  AS ROAS
FROM AD_CAMPAIGNS
GROUP BY ADVERTISER_ID
ORDER BY ADVERTISER_ID;

**Apple Pay Volume

SELECT MERCHANT_ID ,
SUM(CASE WHEN LOWER(PAYMENT_METHOD) = 'apple pay' THEN TRANSACTION_AMOUNT
ELSE  0 END) AS TOTAL_TRANSACTION
FROM TRANSACTIONS
GROUP BY MERCHANT_ID
ORDER BY TOTAL_TRANSACTION DESC;

**App Click-through Rate (CTR)
SELECT APP_ID , 
ROUND(100.0 * 
SUM(CASE WHEN EVENT_TYPE = 'click' THEN 1 ELSE 0 END)/
SUM(CASE WHEN EVENT_TYPE = 'impression' THEN 1 ELSE 0 END) , 2) AS CTR
FROM EVENTS
WHERE TIMESTAMP >='2022-01-01' AND TIMESTAMP < '2023-01-01'
GROUP BY APP_ID;

**Second Day Confirmation

SELECT EMAILS.USER_ID 
FROM EMAILS JOIN TEXTS ON EMAILS.EMAIL_ID = TEXTS.EMAIL_ID
WHERE TEXTS.ACTION_DATE = EMAILS.SIGNUP_DATE + INTERVAL '1 DAY'
AND TEXTS.SIGNUP_ACTION = 'Confirmed';


**User's Third Transaction
SELECT USER_ID , SPEND , TRANSACTION_DATE
FROM (
SELECT USER_ID , SPEND ,TRANSACTION_DATE,
RANK() OVER(
PARTITION BY USER_ID
ORDER BY TRANSACTION_DATE) AS RANK_NUM
FROM TRANSACTIONS) AS TRANS_NUM
WHERE RANK_NUM = 3;

**Compensation Outliers
WITH PAYOUT 
AS (SELECT 
EMPLOYEE_ID , SALARY , TITLE,
(AVG(SALARY) OVER (PARTITION BY TITLE)) *2 
AS DOUBLE_AVERAGE,
(AVG(SALARY) OVER(PARTITION BY TITLE)) /2
AS HALF_AVERAGE
FROM EMPLOYEE_PAY)

SELECT EMPLOYEE_ID , SALARY ,
CASE WHEN SALARY > DOUBLE_AVERAGE THEN 'Overpaid'
WHEN SALARY < HALF_AVERAGE THEN 'Underpaid'
END AS STATUS
FROM PAYOUT
WHERE SALARY > DOUBLE_AVERAGE
OR SALARY < HALF_AVERAGE;

**Sending vs. Opening Snaps

WITH SNAPS_STATISTICS
AS (
SELECT AGE_BREAKDOWN.AGE_BUCKET,
SUM( CASE WHEN ACTIVITIES.ACTIVITY_TYPE = 'send' 
THEN ACTIVITIES.TIME_SPENT ELSE 0 END) AS TIME_SENDING,
SUM( CASE WHEN ACTIVITIES.ACTIVITY_TYPE = 'open' 
THEN ACTIVITIES.TIME_SPENT ELSE 0 END) AS TIME_OPENING
FROM ACTIVITIES  JOIN AGE_BREAKDOWN  
ON ACTIVITIES.USER_ID = AGE_BREAKDOWN.USER_ID
WHERE ACTIVITIES.ACTIVITY_TYPE IN ('send' , 'open')
GROUP BY AGE_BREAKDOWN.AGE_BUCKET
)

SELECT AGE_BUCKET , 
ROUND(100.0 *(TIME_SENDING / (TIME_SENDING + TIME_OPENING)) , 2) AS SEND_PERC,
ROUND(100.0 *(TIME_OPENING / (TIME_SENDING + TIME_OPENING)) , 2) AS OPEN_PERC
FROM SNAPS_STATISTICS;


**Tweets' Rolling Averages

WITH TWEET_COUNT AS (
SELECT 
USER_ID, TWEET_DATE , 
COUNT(TWEET_ID) AS TWEET_NUM
FROM TWEETS 
GROUP BY USER_ID , TWEET_DATE)

SELECT TWEET_DATE , USER_ID , 
ROUND(AVG(TWEET_NUM) OVER(
PARTITION BY USER_ID
ORDER BY TWEET_DATE
ROWS BETWEEN 2 PRECEDING AND CURRENT ROW),2)
AS ROLLING_AVG_3D
FROM TWEET_COUNT;

**Odd and Even Measurements

WITH MEASUREMENT_BY_COUNT AS (
SELECT
CAST (MEASUREMENT_TIME AS DATE) AS MEASUREMENT_DAY,
MEASUREMENT_VALUE,
ROW_NUMBER() OVER(
PARTITION BY CAST(MEASUREMENT_TIME AS DATE)
ORDER BY MEASUREMENT_TIME)
AS MEASUREMENT_NUM 
FROM MEASUREMENTS)

SELECT MEASUREMENT_DAY , 
SUM ( 
CASE WHEN MEASUREMENT_NUM %2 != 0 THEN MEASUREMENT_VALUE
ELSE 0 END) AS ODD_SUM ,
SUM( 
CASE WHEN MEASUREMENT_NUM %2 = 0 THEN MEASUREMENT_VALUE 
ELSE 0 END) AS EVEN_SUM
FROM MEASUREMENT_BY_COUNT 
GROUP BY MEASUREMENT_DAY;


**Highest-Grossing Items

WITH PRODUCT_CATEGORY_SPEND AS(
SELECT CATEGORY, PRODUCT , 
SUM(SPEND) AS TOTAL_SPEND 
FROM PRODUCT_SPEND
WHERE TRANSACTION_DATE >= '01-01-2022'
AND TRANSACTION_DATE < '01-01-2023'
GROUP BY CATEGORY , PRODUCT),

TOP_SPEND AS(
SELECT * ,
RANK() OVER(
PARTITION BY CATEGORY
ORDER BY TOTAL_SPEND DESC) AS RANKING
FROM PRODUCT_CATEGORY_SPEND)

SELECT CATEGORY , PRODUCT , TOTAL_SPEND
FROM TOP_SPEND
WHERE RANKING <= 2
ORDER BY CATEGORY , RANKING;





































































